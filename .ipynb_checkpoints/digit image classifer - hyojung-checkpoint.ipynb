{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 숫자 이미지 인식 문제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 로딩 (train/test split이 바로 지원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 4개를 테스트로 그레이 스케일로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 정보를 이제 일차원 리스트로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# flatten 28*28(이차원) images to a 784 vector(1차원) for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train_cnv = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test_cnv = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "print(num_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지의 스케일을 0-255에서 0-1로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnv = X_train_cnv / 255\n",
    "X_test_cnv = X_test_cnv / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification 결과에 대해 One-hot encoding 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(y_test) # 아래 결과를 one hot encoding으로 바꾸어야 마지막 softmax적용이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train) # one hot encoding을 수행하는 함수가 categorical\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN 모델 빌딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서보드 추가하기:\n",
    "로그 디렉토리를 지정하여 텐서 보드를 실행가능: 로컬 PC의 anaconda command에서  \"tensorboard --logdir c:/Users/hyojung/python-data-tutorial/keras/log\" 수행. 그리고 화면에 나온 http://0.0.0.0:6006 (?)를 브라우저에 copy하여 수행. IE는 잘 안되므로 Firefox에서 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.2810 - acc: 0.9205\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1119 - acc: 0.9683\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0724 - acc: 0.9786\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0513 - acc: 0.9857\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0368 - acc: 0.9896\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0263 - acc: 0.9931\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0212 - acc: 0.9944\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0148 - acc: 0.9965\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0093 - acc: 0.9979\n",
      "Baseline Error: 1.86%\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(X_train_cnv,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=200,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 모델 정확도 분석 (scikit-learn의 score에 해당)\n",
    "scores = model.evaluate(X_test_cnv, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try to load a digit image and see how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using one from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[1])\n",
    "plt.show()\n",
    "\n",
    "input = X_train_cnv[1]\n",
    "X = input.reshape(1,784)\n",
    "pr = model.predict_classes(X)\n",
    "print (pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using digit image from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image conversion to 28*28 and save it \"output.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import PIL.ImageOps \n",
    "from numpy import array\n",
    "\n",
    "class ScaleUtils():\n",
    "    def __init__(self, p, h=28, w=28):\n",
    "        self.im = Image.open(p)\n",
    "        self.size = (h,w)\n",
    "    def toGrey(self):\n",
    "        self.im = self.im.convert(\"L\")\n",
    "        return self\n",
    "    def resize(self):\n",
    "        self.im = self.im.resize(self.size)\n",
    "        return self\n",
    "    def invert(self):\n",
    "        self.im = PIL.ImageOps.invert(self.im)\n",
    "        return self\n",
    "    def getArray(self):\n",
    "        return array(self.im)\n",
    "    def getImage(self):\n",
    "        return self.im\n",
    "    def run(self):\n",
    "        return self.toGrey().resize().getArray()\n",
    "    \n",
    "# this particular one requires invert\n",
    "ScaleUtils(\"./digit_image/test_8_digit.png\").toGrey().resize().invert().getImage().save(\"output.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict conversioned image at \"output.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEolJREFUeJzt3W2MVOd1B/D/mdmFNUvALOAFAw7YQW6RpeJ0i9Paqahcx5i4wu4HZBRFVEIhH2ypqfIhFv1Qf7SqJpE/WK5Ig4Kr1HGk2DJKXWOXRrKjVuDFpfiFJBCK610Dy5thed2dO6cf9hKt8d5zlrkz985y/j8JsTtn752H2f0zs3Pu8zyiqiCieCplD4CIysHwEwXF8BMFxfATBcXwEwXF8BMFxfATBcXwEwXF8BMF1VHknU2T6dqF7iLvsj2I2PWcV1lKZ2f2qUdH8527w/4R0Vot1/ntO3ceN4/xuErFft7Tet0+d4u/p426jAsY0SuTeuByhV9E1gB4BkAVwD+p6tPW13ehG/fI/XnuckqS6dPNul65kuv8HQsWZdZqA4O5zl3tmW/WkxMn7BNUqtm1emIeKp3TnHPbP+PW41q5aYZ5bP3iRbPujU1HR8x6q+zWXZP+2oZf9otIFcCzAB4CsALABhFZ0ej5iKhYeX7nXwXgkKoeVtURAD8BsK45wyKiVssT/kUAPhr3+UB626eIyGYR6ReR/lHke3lLRM3T8nf7VXWrqvapal8n7N99iag4ecI/CGDJuM8Xp7cR0RSQJ/xvA1guIstEZBqAxwDsaM6wiKjVGm71qWpNRJ4AsBNjrb5tqvp+00Z2A/FaeR1LFpv1ZMhup+Vp51Xnt7CVB7jtPIvXLvNaqFYvXhOnzdji9mw7yNXnV9VXAbzapLEQUYF4eS9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQhc7np4klx4bMutvvNqaXVmba6ye4fXxHpduZGjs8nFnL3UuvO3PmjTn13rmrc+bYd+3cd1lTeq8Hn/mJgmL4iYJi+ImCYviJgmL4iYJi+ImCYquvCM4yz25byJk2ax1fv2jfd3XWLLOenDtn1q1WHgB7Wm3OabHe41ad25N97AV7dV69dCnXfU8FfOYnCorhJwqK4ScKiuEnCorhJwqK4ScKiuEnCop9/iI42zV700dlur0jbO3Y8ey7HrW30H7+0H+Y9XlVe0rwmtv6zLq1hbe79HbOabPJqdP2+XPwvmfJmTMtu+9m4TM/UVAMP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVC5+vwicgTAMIAEQE1V7aZvULm3wc5h58Bes36x3pnr/K/9X79Zf/DWlZm1ao/dK68dPWbfubNOgkzLvj5CR5z5+M61Gdb1C1NFMy7y+TNVPdmE8xBRgfiynyiovOFXAK+LyF4R2dyMARFRMfK+7L9PVQdF5BYAb4jIr1T1zfFfkP6nsBkAumBv7URExcn1zK+qg+nfQwBeBrBqgq/Zqqp9qtrXCWciBxEVpuHwi0i3iHzu6scAvgLgvWYNjIhaK8/L/l4AL8tYu6UDwL+o6mtNGRURtVzD4VfVwwD+oIljuWG5fXynX71z8L8bvu8DI/b69L8/zX4fxurTA8DOj/c1XN/nrNu/ZdXDZt17XK21DCrOWgL1y5fturdfwRTAVh9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQXLq7DeRp5QHAFR3NrP3N8tXmsd7y1x0Les261wp8eWBPZm2l025LTrZusqjXyqvMsFugmiR2Pef240XgMz9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQDD9RUOzzTwEnkwtm/et3PpBZ09qlXPetTj8clapZ/ss7vpxZe+43u8xjvesfvGsMULd78RbpsKNRv2hPlZ4K+MxPFBTDTxQUw08UFMNPFBTDTxQUw08UFMNPFBT7/FPA15bc63xFds+5evNs88jkk7O56l4/3JrXvqxzpnmst+x4dd5cs56cPJVZq3R1mcfCWWtAOrO3/wb8dRLaAZ/5iYJi+ImCYviJgmL4iYJi+ImCYviJgmL4iYJy+/wisg3AwwCGVPWu9LYeAC8CWArgCID1qnqmdcOc4pwtuH87et6sV2fNMuvW3HKvT++ty187dtysay17G2wAqM6fn1nz/t0Lqs5zk3Pfpop9bndb9RvAZJ75fwRgzTW3PQlgl6ouB7Ar/ZyIphA3/Kr6JoDT19y8DsD29OPtAB5p8riIqMUa/Z2/V1WPph8fA2C/diSitpP7DT9VVQCaVReRzSLSLyL9o2j//cuIomg0/MdFZCEApH8PZX2hqm5V1T5V7euEPVmCiIrTaPh3ANiYfrwRwCvNGQ4RFcUNv4i8AOC/ANwpIgMisgnA0wAeEJGDAP48/ZyIphC3z6+qGzJK9zd5LDcuzXxLBABwhzOv/dl3XzXrj/c9mlnz+tVeHz/3egDG/Xv/bo933xZv3f3KjBl2vWeOWa8NDF73mIrGK/yIgmL4iYJi+ImCYviJgmL4iYJi+ImC4tLdBfCWefa2mt758T6z/o97X86s3daRr53m8bYPn12xlsi2t/c+WnOmOjttSEty9pxZ91qB3KKbiKYshp8oKIafKCiGnygohp8oKIafKCiGnygo9vkLINM6zfprH+4x6+frl5s5nOviLa+dZ1puonWzvtC5RkFHRs16nl58ZeUK+9z7Pmj43O2Cz/xEQTH8REEx/ERBMfxEQTH8REEx/ERBMfxEQbHPX4D6BXvOuzdv3et3zzT+C39o+b3msd7YqnN7zHpy6to9XD+t0t2dWdv+q9fNY2+pZh8LADsOvmXWz9ezt4f72t1/YR6bOH186bCj421d3g74zE8UFMNPFBTDTxQUw08UFMNPFBTDTxQUw08UlKizfbSIbAPwMIAhVb0rve0pAN8AcHX/5S2qau8jDWCW9Og9Em9nb2/d/bP1S2Z9/ZI/afzOne+vR6ZPt09/JbuX7qrY6/ZXuuz7/rdD/9n4fTu8vRS8vRh0dKSZw5m03boL5/S0TOZrJ/PM/yMAaya4/fuqujL94wafiNqLG35VfROAfRkXEU05eX7nf0JE9ovINhGZ07QREVEhGg3/cwDuALASwFEA3836QhHZLCL9ItI/ihy/HxJRUzUUflU9rqqJqtYB/ADAKuNrt6pqn6r2dcJ+A4eIitNQ+EVk4bhPHwXwXnOGQ0RFcaf0isgLAFYDmCciAwD+DsBqEVkJQAEcAfDNFo6RiFrA7fM3k9fn93qnUs1+oVK/nG9te2+v9+STs5k1r49/JrHXj99w+2qz7vWMOxYuyKzVjh4zj/W0tM+fU8eSxWa99tFAZs37nnnW3NZn1suaz9/sPj8R3YAYfqKgGH6ioBh+oqAYfqKgGH6ioIpdulvEbOdpkpiHWy2v6heWmccmh/7XrhutPMBuDeVdettr5VWX327WawcPZ9bcJabrzpTuqjPt1lnaWy9ntwK9dlhl1iyzbrXyALsF6k3Z/fngXrM+FZbm9vCZnygohp8oKIafKCiGnygohp8oKIafKCiGnyioYvv8qnZP21nKuWPRrZm1mtPHr86ba9aTk6fM+vl69pRhr4//4OI/NOsy3f42JEYfHwAqM2Zk1nTEWUK6bl9bUb9oT0eGV88hOXnSrFd7bzHr1nRm7/qHTrF/Fm8EfOYnCorhJwqK4ScKiuEnCorhJwqK4ScKiuEnCqrYPr+j0p3drwaA2uDHmTVvienklL3XqNUrB4CbJHsdgpPJBfNYr5euV+x6pavLPr3Ra/d64bhkL3menDtn1qtz7G0akzNnMmuV7m7zWG/OfHJ8yKznOfeo2t8T75oU73veDvjMTxQUw08UFMNPFBTDTxQUw08UFMNPFBTDTxSU2+cXkSUAngfQC0ABbFXVZ0SkB8CLAJYCOAJgvapmN3UnoT48bNatXrw377w6f75ZT06cMOtfXfqlzNprH+4xj/W2g16z7B6znmf78eSEvU6BS+zdnq0+vqtiP/fk3f67Y0FvZu1f39lpHnu2bq+DUOmyrytx10FoA5N55q8B+LaqrgDwJQCPi8gKAE8C2KWqywHsSj8noinCDb+qHlXVd9KPhwEcALAIwDoA29Mv2w7gkVYNkoia77p+5xeRpQDuBrAbQK+qHk1LxzD2awERTRGTDr+IzATwMwDfUtVPXfCtqoqx9wMmOm6ziPSLSP8o8v0OR0TNM6nwi0gnxoL/Y1V9Kb35uIgsTOsLAUw4y0JVt6pqn6r2dcJ+k4SIiuOGX0QEwA8BHFDV740r7QCwMf14I4BXmj88ImqVyUzpvRfA1wG8KyJXe1ZbADwN4KcisgnAhwDWeyeSjiqqc7KX0PaWz/a28LZ4rTyPt422Zc+VUbNeuXm2fQJvautpo92Wc2qpN1XaWwK7fiF7urPX2vVUnS2868PZW6f/9Lz9mK+3V2OfEq08jxt+Vf0lgKxm7/3NHQ4RFYVX+BEFxfATBcXwEwXF8BMFxfATBcXwEwVV6NLdWkvsXr6zHHLF6DknzvRPrx/tLXFtTS998NaV5rHelN5n97xk1ofVHvt3fm91Zq0+Yl9j4F0HkKeP7x4vznNPxZlO7Cwrbt33+pln7ft2eI+LtzR4O+AzP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQMrYCVzFmd8zTP565LrPu9W1NebdMdpaoRgsfJ+86gCvqrAdg/B/eKc7j4tg/Yi8bbl1jANjLjuftle8YfNusT5fOzNpALXuuPwBs+vyXzXorfx7y2K27cE5POz/MY/jMTxQUw08UFMNPFBTDTxQUw08UFMNPFBTDTxRUoX3+WdKj90i81b69te+9ragrXV1mPc8W3l6v/cUjb5n12ZWbGr7vVku0nllbu+iL5rFVZy+F5JN86wG0Cvv8RORi+ImCYviJgmL4iYJi+ImCYviJgmL4iYJy1+0XkSUAngfQC0ABbFXVZ0TkKQDfAHB14/stqvpqqwY6lXl9fPd451oM6zoAucnuwydnzpj1xx7eZNbr+z4w6z8f3JtZq2Tu/D7mTP2SWZ9X7Tbra5f8kVF19iuYPcuso037/NdjMpt21AB8W1XfEZHPAdgrIm+kte+r6j+0bnhE1Cpu+FX1KICj6cfDInIAwKJWD4yIWuu6fucXkaUA7gawO73pCRHZLyLbRGROxjGbRaRfRPpHke/lLxE1z6TDLyIzAfwMwLdU9RyA5wDcAWAlxl4ZfHei41R1q6r2qWpfJ+xr3ImoOJMKv4h0Yiz4P1bVlwBAVY+raqKqdQA/ALCqdcMkomZzwy8iAuCHAA6o6vfG3b5w3Jc9CuC95g+PiFrFndIrIvcBeAvAuwCuzpHcAmADxl7yK4AjAL6ZvjmYKeyUXmfarKel2z23esly6/zeufMux26desYM+9QXLzZ87jJdz5Teybzb/0tgwoYse/pEUxiv8CMKiuEnCorhJwqK4ScKiuEnCorhJwoqXwOaJsXr03vXAbRy6e6qM3XVW6K6eucX7ON/fei6x3RVpcu+HLx+yZ7yW7355syaN5XZU11+u1lPDh7Odf4i8JmfKCiGnygohp8oKIafKCiGnygohp8oKIafKKhCt+gWkRMAPhx30zwAJwsbwPVp17G167gAjq1RzRzb51V1/mS+sNDwf+bORfpVta+0ARjadWztOi6AY2tUWWPjy36ioBh+oqDKDv/Wku/f0q5ja9dxARxbo0oZW6m/8xNRecp+5ieikpQSfhFZIyK/FpFDIvJkGWPIIiJHRORdEdknIv0lj2WbiAyJyHvjbusRkTdE5GD694TbpJU0tqdEZDB97PaJyNqSxrZERH4hIh+IyPsi8tfp7aU+dsa4SnncCn/ZLyJVAL8B8ACAAQBvA9igqvZezwURkSMA+lS19J6wiPwpgPMAnlfVu9Lb/h7AaVV9Ov2Pc46qfqdNxvYUgPNl79ycbiizcPzO0gAeAfBXKPGxM8a1HiU8bmU8868CcEhVD6vqCICfAFhXwjjanqq+CeD0NTevA7A9/Xg7xn54CpcxtragqkdV9Z3042EAV3eWLvWxM8ZVijLCvwjAR+M+H0B7bfmtAF4Xkb0isrnswUygd9zOSMcA9JY5mAm4OzcX6ZqdpdvmsWtkx+tm4xt+n3Wfqn4RwEMAHk9f3rYlHfudrZ3aNZPaubkoE+ws/TtlPnaN7njdbGWEfxDAknGfL05vawuqOpj+PQTgZbTf7sPHr26Smv49VPJ4fqeddm6eaGdptMFj1047XpcR/rcBLBeRZSIyDcBjAHaUMI7PEJHu9I0YiEg3gK+g/XYf3gFgY/rxRgCvlDiWT2mXnZuzdpZGyY9d2+14raqF/wGwFmPv+P8WwN+WMYaMcd0O4H/SP++XPTYAL2DsZeAoxt4b2QRgLoBdAA4C+HcAPW00tn/G2G7O+zEWtIUlje0+jL2k3w9gX/pnbdmPnTGuUh43XuFHFBTf8CMKiuEnCorhJwqK4ScKiuEnCorhJwqK4ScKiuEnCur/ATZhd3o/mOvyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 이미지가 output.jpg에 있음. \n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = imread(\"output.jpg\")\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "input = im\n",
    "X = input.reshape(1,784)\n",
    "pr = model.predict_classes(X)\n",
    "print (pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
